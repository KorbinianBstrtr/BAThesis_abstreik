% !TEX root = ../main.tex
\label{section:discussion}
\section{Discussion}

To conclude this thesis, we summarise the main results of incorporating physical constraints into deep learning models. First of all, we empirically showed that the knowledge about scientific principles can improve overall performance significantly. In addition, it also leads to higher alignment of the predictions with the physical constraints even in areas where no training data is available. However, since this was only possible using the determinant and not with the norm constraint, we saw that there is no such guarantee for all physical constraints. One might reason that principles that reveal more complicated underlying structures of the process such as the determinant of a rotation matrix lead to higher improvements, since they are otherwise difficult to learn. This is especially true when only few training data is available. We were also able to show that the proposed methods lead to smaller training error in regions where training data is sparse.\\
\indent When comparing the Penalty Method to the Augmented Lagrangian Method, it is important to note that even though ALM leads to higher performance and showed high potential when terminating training at the right time, there are currently no known methods to the author that estimate hyperparameters well. Since the Penalty Method is easy to understand   and to implement, robust to the physical loss weight and requires less epochs, we advise to first apply this method and only search for good ALM hyperparameters once applying the Penalty Method has shown improvements. Furthermore, we were not able to yield improvements using the method of Physical Projections on any constraint.\\
\indent For future studies, we suggest to explore ways to find better parameters for ALM in order to achieve more consistent results. Since we found that good test performance is already achieved after a fraction of the total number of training epochs, developing new conditions when to terminate the training process is critical and promising to reduce training time and achieve significantly higher performance. It also needs to be checked if the achieved improvements shown in this thesis generalise to other model architectures. Furthermore, we propose the idea of training the model on either additional real or simulated unsupervised data using solely the physical loss. This could yield higher physical feasability of the predictions, which comes with a high probability of increasing overall performance, especially in areas where no training data exists. In addition, the positive effects of the introduced methods need to be validated on real world applications. This includes testing their robustness towards commonly occuring problems, such as inbalanced datasets or noise in the training data.\\






\clearpage

