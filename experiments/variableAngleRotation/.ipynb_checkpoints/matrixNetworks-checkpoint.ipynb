{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "#SBATCH --cpus=1\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --mem=20GB\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=abstreik\n",
    "#SBATCH --time=18:00:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../helper')\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import RotationMatrix\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "tqdm = lambda x: x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "points = pd.read_csv(\"../data/rotated_points_angle.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        hidden_nodes = 5\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(1, hidden_nodes),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_nodes, 1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x_batch):\n",
    "        return self.ff(x_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if model can learn sine function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_sin():\n",
    "    random.seed(234)\n",
    "    model = Net()\n",
    "    opt = Adam(model.parameters())\n",
    "    model.train()\n",
    "    for i in tqdm(range(300000)):\n",
    "        alpha = random.uniform(0, 2*math.pi)\n",
    "        pred = model(torch.Tensor([alpha]))\n",
    "        y_true = math.sin(alpha)\n",
    "        opt.zero_grad()\n",
    "        loss = (pred - y_true) ** 2\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_sin_model(model):\n",
    "    test = np.linspace(0, 2*math.pi, 100)\n",
    "    model.eval()\n",
    "    pred = model(torch.Tensor(np.matrix(test).transpose()))\n",
    "    plt.plot(test, np.sin(test))\n",
    "    plt.plot(test, pred.detach().numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot_sin_model(train_sin())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train nets for matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loader(data, shuffle=True):\n",
    "    X = torch.FloatTensor(data[[\"x1\", \"y1\", \"alpha\"]].values)\n",
    "    y = torch.FloatTensor(data[[\"x2\", \"y2\"]].values)\n",
    "    torch_data = TensorDataset(X, y)\n",
    "    loader = DataLoader(torch_data, batch_size=5, shuffle=shuffle)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def l2_loss(y_pred, y_true, rotation_matrix):\n",
    "    return (y_pred[0] - y_true[0]) ** 2 + (y_pred[1] - y_true[1]) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_pred_loss(x_batch, y_batch, nets, loss_fn):\n",
    "    alphas = x_batch[:, [2]]\n",
    "    matrix_entries = [model(alphas) for model in nets]\n",
    "    loss = 0\n",
    "    preds = []\n",
    "    for i in range(len(alphas)):\n",
    "        predx = matrix_entries[0][i] * x_batch[i][0] + matrix_entries[1][i] * x_batch[i][1]\n",
    "        predy = matrix_entries[2][i] * x_batch[i][0] + matrix_entries[3][i] * x_batch[i][1]\n",
    "        loss += loss_fn((predx, predy), y_batch[i], [[matrix_entries[0][i], matrix_entries[1][i]], [matrix_entries[2][i], matrix_entries[3][i]]])\n",
    "        preds.append((predx.item(), predy.item()))\n",
    "    loss /= len(alphas)\n",
    "    return {\"loss\": loss, \"preds\": preds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_loss(x_batch, y_batch, nets, loss_fn):\n",
    "    return calc_pred_loss(x_batch, y_batch, nets, loss_fn)[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"../data/test.csv\")\n",
    "test_data = test_data[test_data.index % 20 == 0]\n",
    "test_loader = get_loader(test_data, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(net_ensemble, loss_fn=l2_loss, visualizePreds=False):\n",
    "    test_preds = []\n",
    "    test_true = []\n",
    "    all_model_preds = []\n",
    "    avg_test_loss = 0.0\n",
    "    for nets in net_ensemble:\n",
    "        model_preds = []\n",
    "        for model in nets:\n",
    "            model.eval()\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            result = calc_pred_loss(x_batch, y_batch, nets, loss_fn)\n",
    "            model_preds += result[\"preds\"]\n",
    "            avg_test_loss += result[\"loss\"]\n",
    "            test_true += list(y_batch)\n",
    "        all_model_preds.append(model_preds)\n",
    "        if visualizePreds:\n",
    "            print(\"model preds:\")\n",
    "            plot_predictions(model_preds)\n",
    "    avg_test_loss /= len(test_loader) * len(net_ensemble)\n",
    "    for i in range(len(all_model_preds[0])):\n",
    "        predx = 0\n",
    "        predy = 0\n",
    "        for model_preds in all_model_preds:\n",
    "            predx += model_preds[i][0]\n",
    "            predy += model_preds[i][1]\n",
    "        predx /= len(all_model_preds)\n",
    "        predy /= len(all_model_preds)\n",
    "        test_preds.append((predx, predy))\n",
    "    if visualizePreds:\n",
    "        print(\"total preds:\")\n",
    "        plot_predictions(test_preds)\n",
    "    test_loss = 0\n",
    "    for y_pred, y_true in zip(test_preds, test_true):\n",
    "        test_loss += loss_fn(y_pred, y_true, [[float('NaN'), float('NaN')], [float('NaN'), float('NaN')]])\n",
    "    test_loss /= len(test_preds)\n",
    "    return {\"loss\": test_loss.item(), \"preds\": test_preds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_points_train_val, loss_fn, includeTests=False, prints=False):\n",
    "    train_val_points = points.head(n_points_train_val)\n",
    "    n_folds = min(n_points_train_val, 10)\n",
    "    fold_indices = [(range(n_points_train_val), range(n_points_train_val))]\n",
    "    if n_folds > 1:\n",
    "        kf = KFold(n_folds)\n",
    "        fold_indices = kf.split(train_val_points)\n",
    "\n",
    "    train_loader = []\n",
    "    val_loader = []\n",
    "    for train_index, val_index in fold_indices:\n",
    "        train_loader.append(get_loader(points.loc[train_index]))\n",
    "        val_loader.append(get_loader(points.loc[val_index]))\n",
    "    \n",
    "    nets = [[Net() for _ in range(4)] for _ in range(n_folds)]\n",
    "    opts = []\n",
    "    for matrixnets in nets:\n",
    "        optrow = []\n",
    "        for model in matrixnets:\n",
    "            optrow.append(Adam(model.parameters()))\n",
    "        opts.append(optrow)\n",
    "    val_losses = []\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    best_test_preds = None\n",
    "    epochs = []\n",
    "    epoch = 0\n",
    "    epochs_per_validation = 100 if n_points_train_val > 10 else (10 if n_points_train_val > 5 else 3)\n",
    "    while True:\n",
    "        epoch_val_loss = 0\n",
    "        epoch_train_loss = 0\n",
    "        validate = (epoch % epochs_per_validation == 0)\n",
    "        for fold in range(n_folds):\n",
    "            # training\n",
    "            for model in nets[fold]:\n",
    "                model.train()\n",
    "            for x_batch, y_batch in train_loader[fold]:\n",
    "                loss = calc_loss(x_batch, y_batch, nets[fold], loss_fn)\n",
    "                for opt in opts[fold]:\n",
    "                    opt.zero_grad()\n",
    "                loss.backward()\n",
    "                for opt in opts[fold]:\n",
    "                    opt.step()\n",
    "            # validation\n",
    "            if validate:\n",
    "                for model in nets[fold]:\n",
    "                    model.eval()\n",
    "                val_loss = 0\n",
    "                train_loss = 0\n",
    "                for x_batch, y_batch in val_loader[fold]:\n",
    "                    val_loss += calc_loss(x_batch, y_batch, nets[fold], loss_fn)\n",
    "                for x_batch, y_batch in train_loader[fold]:\n",
    "                    train_loss += calc_loss(x_batch, y_batch, nets[fold], loss_fn)\n",
    "                val_loss /= len(val_loader[fold])\n",
    "                train_loss /= len(train_loader[fold])\n",
    "                epoch_val_loss += val_loss\n",
    "                epoch_train_loss += train_loss\n",
    "\n",
    "        if validate:\n",
    "            epochs.append(epoch)\n",
    "            epoch_val_loss /= n_folds\n",
    "            epoch_train_loss /= n_folds\n",
    "            val_losses.append(epoch_val_loss.item())\n",
    "            train_losses.append(epoch_train_loss.item())\n",
    "            if includeTests:\n",
    "                test_result = test(nets, visualizePreds=False)#(epoch%1000 == 0))\n",
    "                test_losses.append(test_result[\"loss\"])\n",
    "                if len(val_losses) > 1 and (best_test_preds is None or val_losses[-1] < min(val_losses[1:-1])):\n",
    "                    best_test_preds = test_result[\"preds\"]\n",
    "        if prints and epoch % 100 == 0:\n",
    "            print(\"Epoch {}:\\tTrain {}\\tVal {}\\tTest {}\".format(epoch, train_losses[-1], val_losses[-1], test_losses[-1]))\n",
    "        epoch += 1\n",
    "        reference_loss_index = 1000 // epochs_per_validation\n",
    "        if epoch > max(n_points_train_val * 200, 8000) and val_losses[-1] >= val_losses[-reference_loss_index]:\n",
    "            break\n",
    "    \n",
    "    return {\"nets\": nets, \n",
    "            \"train_loss\": train_losses, \n",
    "            \"val_loss\": val_losses, \n",
    "            \"test_loss\": test_losses, \n",
    "            \"best_test_preds\": best_test_preds,\n",
    "            \"epochs\": epochs\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def visualize_train(train_results):\n",
    "    for i, train_result in enumerate(train_results):\n",
    "        plt.plot(train_result[\"epochs\"], train_result[\"train_loss\"], label='Training{}'.format(i))\n",
    "        plt.plot(train_result[\"epochs\"], train_result[\"val_loss\"], label='Validation{}'.format(i))\n",
    "        if len(train_result[\"test_loss\"]):\n",
    "            plt.plot(train_result[\"epochs\"], train_result[\"test_loss\"], label='Test{}'.format(i))\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(preds):\n",
    "    plt.figure()\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.ylim(-1.2, 1.2)\n",
    "    plt.xlim(-1.2, 1.2)\n",
    "    for i, pred in enumerate(preds):\n",
    "        test_point = test_data.iloc[i]\n",
    "        plt.plot([test_point[\"x1\"], test_point[\"x2\"]], [test_point[\"y1\"], test_point[\"y2\"]], color=\"green\", linewidth=0.5)\n",
    "        plt.plot([pred[0], test_point[\"x2\"]], [pred[1], test_point[\"y2\"]], color=\"red\", linewidth=0.5)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start calculation for 31 points.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-249-dc76456d53d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start calculation for {} points.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_points_train_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstarttime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_points_train_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincludeTests\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mvisualize_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_result\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mtrain_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-246-697e72a7cd04>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(n_points_train_val, loss_fn, includeTests, prints)\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0;31m# validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/korbinianabstreiter/anaconda/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for n_points_train_val in range(1, 41):\n",
    "    print(\"Start calculation for {} points.\".format(n_points_train_val))\n",
    "    starttime = time.time()\n",
    "    train_result = train(n_points_train_val, l2_loss, includeTests=True, prints=False)\n",
    "    visualize_train([train_result])\n",
    "    del train_result[\"nets\"]\n",
    "    results.append([n_points_train_val, str(train_result), time.time() - starttime])\n",
    "    if n_points_train_val >= 10 and n_points_train_val % 5 == 0:\n",
    "        df = pd.DataFrame(results, columns=[\"n_points_train_val\", \"train_result\", \"execution_time\"])\n",
    "        df.to_csv(\"train_limited_data_results_{}.csv\".format(n_points_train_val), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add different loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_loss(y_pred, y_true, rotation_matrix):\n",
    "    return (l2_loss(y_pred, (0,0), np.zeros((2,2))) - 1) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def det_loss(y_pred, y_true, rotation_matrix):\n",
    "    det = rotation_matrix[0][0] * rotation_matrix[1][1] - rotation_matrix[0][1] * rotation_matrix[1][0]\n",
    "    return (det - 1) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first weight is for l2_loss, second weight for det_loss, third for norm loss\n",
    "def get_mixed_lossfn(weigths):\n",
    "    def mixed_loss(y_pred, y_true, rotation_matrix):\n",
    "        l0 = l2_loss(y_pred, y_true, rotation_matrix)\n",
    "        l1 = det_loss(y_pred, y_true, rotation_matrix)\n",
    "        l2 = norm_loss(y_pred, y_true, rotation_matrix)\n",
    "        return weigths[0] * l0 + weigths[1] * l1 + weigths[2] * l2\n",
    "    return mixed_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    n_points_train_val = 5\n",
    "    train_result_mixed = train(n_points_train_val, get_mixed_lossfn((1, 2, 4)), includeTests=True, prints=True)\n",
    "    visualize_train([train_result, train_result_mixed])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results: \n",
    "(1, 2, 0.2) is more consistent throughout training\n",
    "(1, 2, 8) is worse\n",
    "(1, 4, 0.2) really bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
