{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "#SBATCH --cpus=1\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --mem=20GB\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=abstreik\n",
    "#SBATCH --time=45:00:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../helper')\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import RotationMatrix\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "tqdm = lambda x: x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "points = pd.read_csv(\"../data/rotated_points_angle.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, n_hidden=None):\n",
    "        super().__init__()\n",
    "        hidden_nodes = 50 if n_hidden is None else n_hidden\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(1, hidden_nodes),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_nodes, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x_batch):\n",
    "        return self.ff(x_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if model can learn sine function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_sin():\n",
    "    random.seed(234)\n",
    "    model = Net()\n",
    "    opt = Adam(model.parameters())\n",
    "    model.train()\n",
    "    for i in tqdm(range(300000)):\n",
    "        alpha = random.uniform(0, 2*math.pi)\n",
    "        pred = model(torch.Tensor([alpha]))\n",
    "        y_true = math.sin(alpha)\n",
    "        opt.zero_grad()\n",
    "        loss = (pred - y_true) ** 2\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_sin_model(model):\n",
    "    test = np.linspace(0, 2*math.pi, 100)\n",
    "    model.eval()\n",
    "    pred = model(torch.Tensor(np.matrix(test).transpose()))\n",
    "    plt.plot(test, np.sin(test))\n",
    "    plt.plot(test, pred.detach().numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_matrix_nets(nets):\n",
    "    test = np.linspace(0, 2*math.pi, 100)\n",
    "    for model in nets:\n",
    "        model.eval()\n",
    "    fig, ax = plt.subplots(2, 2)\n",
    "    ax[0, 0].plot(test, np.cos(test))\n",
    "    ax[0, 0].plot(test, nets[0](torch.Tensor(np.matrix(test).transpose())).detach().numpy())\n",
    "    ax[0, 1].plot(test, -np.sin(test))\n",
    "    ax[0, 1].plot(test, nets[1](torch.Tensor(np.matrix(test).transpose())).detach().numpy())\n",
    "    ax[1, 0].plot(test, np.sin(test))\n",
    "    ax[1, 0].plot(test, nets[2](torch.Tensor(np.matrix(test).transpose())).detach().numpy())\n",
    "    ax[1, 1].plot(test, np.cos(test))\n",
    "    ax[1, 1].plot(test, nets[3](torch.Tensor(np.matrix(test).transpose())).detach().numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot_sin_model(train_sin())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train nets for matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loader(data, shuffle=True):\n",
    "    X = torch.FloatTensor(data[[\"x1\", \"y1\", \"alpha\"]].values)\n",
    "    y = torch.FloatTensor(data[[\"x2\", \"y2\"]].values)\n",
    "    torch_data = TensorDataset(X, y)\n",
    "    loader = DataLoader(torch_data, batch_size=5, shuffle=shuffle)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def l2_loss(y_pred, y_true, rotation_matrix):\n",
    "    return (y_pred[0] - y_true[0]) ** 2 + (y_pred[1] - y_true[1]) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_pred_loss(x_batch, y_batch, nets, loss_fn):\n",
    "    alphas = x_batch[:, [2]]\n",
    "    matrix_entries = [model(alphas) for model in nets]\n",
    "    loss = 0\n",
    "    preds = []\n",
    "    for i in range(len(alphas)):\n",
    "        predx = matrix_entries[0][i] * x_batch[i][0] + matrix_entries[1][i] * x_batch[i][1]\n",
    "        predy = matrix_entries[2][i] * x_batch[i][0] + matrix_entries[3][i] * x_batch[i][1]\n",
    "        loss += loss_fn((predx, predy), y_batch[i], [[matrix_entries[0][i], matrix_entries[1][i]], [matrix_entries[2][i], matrix_entries[3][i]]])\n",
    "        preds.append((predx.item(), predy.item()))\n",
    "    loss /= len(alphas)\n",
    "    return {\"loss\": loss, \"preds\": preds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_loss(x_batch, y_batch, nets, loss_fn):\n",
    "    return calc_pred_loss(x_batch, y_batch, nets, loss_fn)[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"../data/test.csv\")\n",
    "# test_data = test_data[test_data.index % 20 == 0]\n",
    "test_loader = get_loader(test_data, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(net_ensemble, loss_fn=l2_loss, visualizePreds=False):\n",
    "    test_preds = []\n",
    "    test_true = []\n",
    "    all_model_preds = []\n",
    "    avg_test_loss = 0.0\n",
    "    for nets in net_ensemble:\n",
    "        model_preds = []\n",
    "        for model in nets:\n",
    "            model.eval()\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            result = calc_pred_loss(x_batch, y_batch, nets, loss_fn)\n",
    "            model_preds += result[\"preds\"]\n",
    "            avg_test_loss += result[\"loss\"]\n",
    "            test_true += list(y_batch)\n",
    "        all_model_preds.append(model_preds)\n",
    "        if visualizePreds:\n",
    "            print(\"model preds:\")\n",
    "            plot_predictions(model_preds)\n",
    "    avg_test_loss /= len(test_loader) * len(net_ensemble)\n",
    "    for i in range(len(all_model_preds[0])):\n",
    "        predx = 0\n",
    "        predy = 0\n",
    "        for model_preds in all_model_preds:\n",
    "            predx += model_preds[i][0]\n",
    "            predy += model_preds[i][1]\n",
    "        predx /= len(all_model_preds)\n",
    "        predy /= len(all_model_preds)\n",
    "        test_preds.append((predx, predy))\n",
    "    if visualizePreds:\n",
    "        print(\"total preds:\")\n",
    "        plot_predictions(test_preds)\n",
    "    test_loss = 0\n",
    "    for y_pred, y_true in zip(test_preds, test_true):\n",
    "        test_loss += loss_fn(y_pred, y_true, [[float('NaN'), float('NaN')], [float('NaN'), float('NaN')]])\n",
    "    test_loss /= len(test_preds)\n",
    "    return {\"loss\": test_loss.item(), \"preds\": test_preds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(n_points_train_val, loss_fn, includeTests=False, prints=False, lastTrainResult=None, nEpochs=None, minEpochs=8000, hidden_nodes=None):\n",
    "    torch.manual_seed(0)\n",
    "    train_val_points = points.head(n_points_train_val)\n",
    "    n_folds = min(n_points_train_val, 10)\n",
    "    fold_indices = [(range(n_points_train_val), range(n_points_train_val))]\n",
    "    if n_folds > 1:\n",
    "        kf = KFold(n_folds, random_state=0)\n",
    "        fold_indices = kf.split(train_val_points)\n",
    "\n",
    "    train_loader = []\n",
    "    val_loader = []\n",
    "    for train_index, val_index in fold_indices:\n",
    "        train_loader.append(get_loader(points.loc[train_index]))\n",
    "        val_loader.append(get_loader(points.loc[val_index]))\n",
    "    \n",
    "    nets = [[Net(n_hidden=hidden_nodes) for _ in range(4)] for _ in range(n_folds)] if lastTrainResult is None else lastTrainResult[\"nets\"]\n",
    "    opts = []\n",
    "    if lastTrainResult is None:\n",
    "        for matrixnets in nets:\n",
    "            optrow = []\n",
    "            for model in matrixnets:\n",
    "                optrow.append(Adam(model.parameters()))\n",
    "            opts.append(optrow)\n",
    "    else:\n",
    "        opts = lastTrainResult[\"opts\"]\n",
    "    val_losses = [] if lastTrainResult is None else lastTrainResult[\"val_loss\"]\n",
    "    train_losses = [] if lastTrainResult is None else lastTrainResult[\"train_loss\"]\n",
    "    test_losses = [] if lastTrainResult is None else lastTrainResult[\"test_loss\"]\n",
    "    best_test_preds = None if lastTrainResult is None else lastTrainResult[\"best_test_preds\"]\n",
    "    epochs = [] if lastTrainResult is None else lastTrainResult[\"epochs\"]\n",
    "    epoch = 0 if lastTrainResult is None else (epochs[-1] + 1)\n",
    "    start_epoch = epoch\n",
    "    epochs_per_validation = 500#100 if n_points_train_val > 10 else (10 if n_points_train_val > 5 else 3)\n",
    "    while True:\n",
    "        epoch_val_loss = 0\n",
    "        epoch_train_loss = 0\n",
    "        validate = (epoch % epochs_per_validation == 0)\n",
    "        for fold in range(n_folds):\n",
    "            # training\n",
    "            for model in nets[fold]:\n",
    "                model.train()\n",
    "            for x_batch, y_batch in train_loader[fold]:\n",
    "                loss = calc_loss(x_batch, y_batch, nets[fold], loss_fn)\n",
    "                for opt in opts[fold]:\n",
    "                    opt.zero_grad()\n",
    "                loss.backward()\n",
    "                for opt in opts[fold]:\n",
    "                    opt.step()\n",
    "            # validation\n",
    "            if validate:\n",
    "                for model in nets[fold]:\n",
    "                    model.eval()\n",
    "                val_loss = 0\n",
    "                train_loss = 0\n",
    "                for x_batch, y_batch in val_loader[fold]:\n",
    "                    val_loss += calc_loss(x_batch, y_batch, nets[fold], l2_loss)\n",
    "                for x_batch, y_batch in train_loader[fold]:\n",
    "                    train_loss += calc_loss(x_batch, y_batch, nets[fold], loss_fn)\n",
    "                val_loss /= len(val_loader[fold])\n",
    "                train_loss /= len(train_loader[fold])\n",
    "                epoch_val_loss += val_loss\n",
    "                epoch_train_loss += train_loss\n",
    "\n",
    "        if validate:\n",
    "            epochs.append(epoch)\n",
    "            epoch_val_loss /= n_folds\n",
    "            epoch_train_loss /= n_folds\n",
    "            val_losses.append(epoch_val_loss.item())\n",
    "            train_losses.append(epoch_train_loss.item())\n",
    "            if includeTests:\n",
    "                test_result = test(nets, visualizePreds=False)#(epoch%1000 == 0))\n",
    "                test_losses.append(test_result[\"loss\"])\n",
    "                if len(val_losses) > 1 and (best_test_preds is None or val_losses[-1] < min(val_losses[1:-1])):\n",
    "                    best_test_preds = test_result[\"preds\"]\n",
    "        if prints and epoch % 500 == 0:\n",
    "            print(\"Epoch {}:\\tTrain {}\\tVal {}\\tTest {}\".format(epoch, train_losses[-1], val_losses[-1], test_losses[-1]))\n",
    "        epoch += 1\n",
    "        reference_loss_index = 1000 // epochs_per_validation\n",
    "        if (nEpochs is None and epoch > max(n_points_train_val * 200, minEpochs) and val_losses[-1] >= val_losses[-reference_loss_index]) or (nEpochs is not None and epoch - start_epoch > nEpochs):\n",
    "            break\n",
    "    \n",
    "    return {\"nets\": nets, \n",
    "            \"opts\": opts,\n",
    "            \"train_loss\": train_losses, \n",
    "            \"val_loss\": val_losses, \n",
    "            \"test_loss\": test_losses, \n",
    "            \"best_test_preds\": best_test_preds,\n",
    "            \"epochs\": epochs\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def visualize_train(train_results, keys=[\"train_loss\", \"val_loss\", \"test_loss\"]):\n",
    "    for i, train_result in enumerate(train_results):\n",
    "        for key in keys:\n",
    "            plt.plot(train_result[\"epochs\"], train_result[key], label='{}_{}'.format(key, i))\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_predictions(preds):\n",
    "    plt.figure()\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.ylim(-1.2, 1.2)\n",
    "    plt.xlim(-1.2, 1.2)\n",
    "    for i, pred in enumerate(preds):\n",
    "        test_point = test_data.iloc[i]\n",
    "        plt.plot([test_point[\"x1\"], test_point[\"x2\"]], [test_point[\"y1\"], test_point[\"y2\"]], color=\"green\", linewidth=0.5)\n",
    "        plt.plot([pred[0], test_point[\"x2\"]], [pred[1], test_point[\"y2\"]], color=\"red\", linewidth=0.5)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with n points until convergence using l2_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare different numbers of hidden nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_points_train_val = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def try_different_hidden_nodes():\n",
    "    results_hidden_nodes = []\n",
    "    for n_hidden in [5, 10, 20, 50, 100]:\n",
    "        print(\"Start calculation for {} hidden nodes.\".format(n_hidden))\n",
    "        nEpochs = 30000 if n_hidden < 50 else 70000\n",
    "        train_result = train(n_points_train_val, l2_loss, includeTests=True, prints=True, nEpochs=nEpochs, hidden_nodes=n_hidden)\n",
    "        del train_result[\"nets\"]\n",
    "        del train_result[\"opts\"]\n",
    "        results_hidden_nodes.append([n_hidden, str(train_result)])\n",
    "    results_hidden_nodes = pd.DataFrame(results_hidden_nodes, columns=[\"n_hidden\", \"train_result\"])\n",
    "    results_hidden_nodes.to_csv(\"results_hidden_nodes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try_different_hidden_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_hidden_nodes = pd.read_csv(\"results_hidden_nodes.csv\")\n",
    "results_hidden_nodes[\"train_result\"] = results_hidden_nodes.apply(lambda row: eval(row[\"train_result\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize_train(results_hidden_nodes[\"train_result\"], keys=[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: Choose 50 hidden nodes (tradeoff between minimum validation loss and epochs to reach it)\n",
    "Difficulty: Validation loss with few data is unreliable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate for different numbers of points and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def try_different_n_data():\n",
    "    results_limited_data = []\n",
    "    for n_points_train_val in range(1, 36):\n",
    "        print(\"Start calculation for {} points.\".format(n_points_train_val))\n",
    "        train_result = train(n_points_train_val, l2_loss, includeTests=True, prints=True, minEpochs=12000)\n",
    "        del train_result[\"nets\"]\n",
    "        del train_result[\"opts\"]\n",
    "        results_limited_data.append([n_points_train_val, str(train_result)])\n",
    "        if n_points_train_val >= 20 and n_points_train_val % 5 == 0:\n",
    "            df = pd.DataFrame(results_limited_data, columns=[\"n_points_train_val\", \"train_result\"])\n",
    "            df.to_csv(\"train_limited_data_results_{}.csv\".format(n_points_train_val), index=False)\n",
    "    results_limited_data = pd.DataFrame(results_limited_data, columns=[\"n_points_train_val\", \"train_result\"])\n",
    "    results_limited_data.to_csv(\"results_limited_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try_different_n_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_limited_data = pd.read_csv(\"train_limited_data_results_35.csv\", index_col=\"n_points_train_val\")\n",
    "results_limited_data[\"train_result\"] = results_limited_data.apply(lambda row: eval(row[\"train_result\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110c4c898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(results_limited_data.index, results_limited_data.apply(lambda x: min(x[\"train_result\"][\"test_loss\"]), axis=1))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npwgX1+GCL9AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11af47c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(results_limited_data.index, results_limited_data.apply(lambda x: min(x[\"train_result\"][\"val_loss\"]), axis=1))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: For at least the first 11 data points, the rotation is approximated well, validation loss again does not reflect test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add different loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choose a specific number of points to further experiment with\n",
    "n_points_train_val = 10\n",
    "train_result = results_limited_data[\"train_result\"][n_points_train_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_loss(y_pred, y_true, rotation_matrix):\n",
    "    return (l2_loss(y_pred, (0,0), np.zeros((2,2))) - 1) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def det_loss(y_pred, y_true, rotation_matrix):\n",
    "    det = rotation_matrix[0][0] * rotation_matrix[1][1] - rotation_matrix[0][1] * rotation_matrix[1][0]\n",
    "    return (det - 1) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first weight is for l2_loss, second weight for det_loss, third for norm loss\n",
    "def get_mixed_lossfn(weigths):\n",
    "    def mixed_loss(y_pred, y_true, rotation_matrix):\n",
    "        l0 = l2_loss(y_pred, y_true, rotation_matrix)\n",
    "        l1 = det_loss(y_pred, y_true, rotation_matrix)\n",
    "        l2 = norm_loss(y_pred, y_true, rotation_matrix)\n",
    "        return weigths[0] * l0 + weigths[1] * l1 + weigths[2] * l2\n",
    "    return mixed_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def try_different_det_loss():\n",
    "    results_det_loss = []\n",
    "    for det_loss_weight in [0.4, 1, 2, 3, 4]:\n",
    "        weights = (1, det_loss_weight, 0)\n",
    "        print(\"Start calculation for weights = {}.\".format(weights))\n",
    "        train_result_tmp = train(n_points_train_val, get_mixed_lossfn(weights), includeTests=True, prints=True, nEpochs=40000)\n",
    "        del train_result_tmp[\"nets\"]\n",
    "        del train_result_tmp[\"opts\"]\n",
    "        results_det_loss.append([n_hidden, str(train_result_tmp)])\n",
    "    results_det_loss = pd.DataFrame(results_det_loss, columns=[\"loss_weights\", \"train_result\"])\n",
    "    results_det_loss.to_csv(\"results_det_loss.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try_different_det_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def try_different_norm_loss():\n",
    "    results_det_loss = []\n",
    "    for norm_loss_weight in [0.03, 0.1, 0.2, 0.4]:\n",
    "        weights = (1, 0, norm_loss_weight)\n",
    "        print(\"Start calculation for weights = {}.\".format(weights))\n",
    "        train_result_tmp = train(n_points_train_val, get_mixed_lossfn(weights), includeTests=True, prints=True, nEpochs=40000)\n",
    "        del train_result_tmp[\"nets\"]\n",
    "        del train_result_tmp[\"opts\"]\n",
    "        results_det_loss.append([n_hidden, str(train_result_tmp)])\n",
    "    results_det_loss = pd.DataFrame(results_det_loss, columns=[\"loss_weights\", \"train_result\"])\n",
    "    results_det_loss.to_csv(\"results_norm_loss.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try_different_norm_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_result_mixed = train(n_points_train_val, get_mixed_lossfn((1, 2, 0.2)), includeTests=True, prints=True, nEpochs=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_result_mixed = train(n_points_train_val, get_mixed_lossfn((1, 0.2, 0.1)), includeTests=True, prints=True, nEpochs=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_result_mixed = train(n_points_train_val, get_mixed_lossfn((1, 0, 0.1)), includeTests=True, prints=True, nEpochs=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#visualize_train([train_result, train_result_mixed])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results: \n",
    "(1, 2, 0.2) is better, converges to 0.18 test loss\n",
    "(1, 2, 8) is worse\n",
    "(1, 4, 0.2) really bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEXT: Try different weights, try dynamically changing loss functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
