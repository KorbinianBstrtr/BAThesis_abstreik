{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "#SBATCH --cpus=1\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --mem=20GB\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=abstreik\n",
    "#SBATCH --time=18:00:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../helper')\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import RotationMatrix\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "tqdm = lambda x: x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "points = pd.read_csv(\"../data/rotated_points_angle.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        hidden_nodes = 5\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(1, hidden_nodes),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_nodes, 1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x_batch):\n",
    "        return self.ff(x_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if model can learn sine function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_sin():\n",
    "    random.seed(234)\n",
    "    model = Net()\n",
    "    opt = Adam(model.parameters())\n",
    "    model.train()\n",
    "    for i in tqdm(range(300000)):\n",
    "        alpha = random.uniform(0, 2*math.pi)\n",
    "        pred = model(torch.Tensor([alpha]))\n",
    "        y_true = math.sin(alpha)\n",
    "        opt.zero_grad()\n",
    "        loss = (pred - y_true) ** 2\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_sin_model(model):\n",
    "    test = np.linspace(0, 2*math.pi, 100)\n",
    "    model.eval()\n",
    "    pred = model(torch.Tensor(np.matrix(test).transpose()))\n",
    "    plt.plot(test, np.sin(test))\n",
    "    plt.plot(test, pred.detach().numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot_sin_model(train_sin())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train nets for matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loader(data):\n",
    "    X = torch.FloatTensor(data[[\"x1\", \"y1\", \"alpha\"]].values)\n",
    "    y = torch.FloatTensor(data[[\"x2\", \"y2\"]].values)\n",
    "    torch_data = TensorDataset(X, y)\n",
    "    loader = DataLoader(torch_data, batch_size=5, shuffle=True)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def l2_loss(y_pred, y_true, rotation_matrix):\n",
    "    return (y_pred[0] - y_true[0]) ** 2 + (y_pred[1] - y_true[1]) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_pred_loss(x_batch, y_batch, nets, loss_fn):\n",
    "    alphas = x_batch[:, [2]]\n",
    "    matrix_entries = [model(alphas) for model in nets]\n",
    "    loss = 0\n",
    "    preds = []\n",
    "    for i in range(len(alphas)):\n",
    "        predx = matrix_entries[0][i] * x_batch[i][0] + matrix_entries[1][i] * x_batch[i][1]\n",
    "        predy = matrix_entries[2][i] * x_batch[i][0] + matrix_entries[3][i] * x_batch[i][1]\n",
    "        loss += loss_fn((predx, predy), y_batch[i], [[matrix_entries[0][i], matrix_entries[1][i]], [matrix_entries[2][i], matrix_entries[3][i]]])\n",
    "        preds.append((predx.item(), predy.item()))\n",
    "    loss /= len(alphas)\n",
    "    return {\"loss\": loss, \"preds\": preds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_loss(x_batch, y_batch, nets, loss_fn):\n",
    "    return calc_pred_loss(x_batch, y_batch, nets, loss_fn)[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"../data/test.csv\")\n",
    "test_loader = get_loader(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(net_ensemble, loss_fn=l2_loss):\n",
    "    test_preds = []\n",
    "    test_true = []\n",
    "    all_model_preds = []\n",
    "    for nets in net_ensemble:\n",
    "        model_preds = []\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            result = calc_pred_loss(x_batch, y_batch, nets, loss_fn)\n",
    "            model_preds += result[\"preds\"]\n",
    "            test_true += list(y_batch)\n",
    "        all_model_preds.append(model_preds)\n",
    "    for i in range(len(all_model_preds[0])):\n",
    "        predx = 0\n",
    "        predy = 0\n",
    "        for model_preds in all_model_preds:\n",
    "            predx += model_preds[i][0]\n",
    "            predy += model_preds[i][1]\n",
    "        predx /= len(all_model_preds)\n",
    "        predy /= len(all_model_preds)\n",
    "        test_preds.append((predx, predy))\n",
    "    test_loss = 0\n",
    "    for y_pred, y_true in zip(test_preds, test_true):\n",
    "        test_loss += loss_fn(y_pred, y_true, [[float('NaN'), float('NaN')], [float('NaN'), float('NaN')]])\n",
    "    test_loss /= len(test_preds)\n",
    "    return {\"loss\": test_loss.item(), \"preds\": test_preds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(n_points_train_val, loss_fn, includeTests=False, prints=False):\n",
    "    train_val_points = points.head(n_points_train_val)\n",
    "    n_folds = min(n_points_train_val, 5)\n",
    "    fold_indices = [([0], [0])]\n",
    "    if n_points_train_val > 1:\n",
    "        kf = KFold(n_folds)\n",
    "        fold_indices = kf.split(train_val_points)\n",
    "\n",
    "    train_loader = []\n",
    "    val_loader = []\n",
    "    for train_index, val_index in fold_indices:\n",
    "        train_loader.append(get_loader(points.loc[train_index]))\n",
    "        val_loader.append(get_loader(points.loc[val_index]))\n",
    "    \n",
    "    nets = [[Net() for _ in range(4)] for _ in range(n_folds)]\n",
    "    opts = [[Adam(model.parameters()) for model in matrixnets] for matrixnets in nets]\n",
    "    val_losses = []\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    best_test_preds = None\n",
    "    epochs = []\n",
    "    epoch = 0\n",
    "    epochs_per_validation = 100 if n_points_train_val > 10 else (10 if n_points_train_val > 5 else 3)\n",
    "    while True:\n",
    "        epoch_val_loss = 0\n",
    "        epoch_train_loss = 0\n",
    "        validate = (epoch % epochs_per_validation == 0)\n",
    "        for fold in range(n_folds):\n",
    "            # training\n",
    "            for model in nets[fold]:\n",
    "                model.train()\n",
    "            for x_batch, y_batch in train_loader[fold]:\n",
    "                loss = calc_loss(x_batch, y_batch, nets[fold], loss_fn)\n",
    "                for opt in opts[fold]:\n",
    "                    opt.zero_grad()\n",
    "                loss.backward()\n",
    "                for opt in opts[fold]:\n",
    "                    opt.step()\n",
    "            # validation\n",
    "            if validate:\n",
    "                for model in nets[fold]:\n",
    "                    model.eval()\n",
    "                val_loss = 0\n",
    "                train_loss = 0\n",
    "                for x_batch, y_batch in val_loader[fold]:\n",
    "                    val_loss += calc_loss(x_batch, y_batch, nets[fold], l2_loss)\n",
    "                for x_batch, y_batch in train_loader[fold]:\n",
    "                    train_loss += calc_loss(x_batch, y_batch, nets[fold], loss_fn)\n",
    "                val_loss /= len(val_loader[fold])\n",
    "                train_loss /= len(train_loader[fold])\n",
    "                epoch_val_loss += val_loss\n",
    "                epoch_train_loss += train_loss\n",
    "\n",
    "        if validate:\n",
    "            epochs.append(epoch)\n",
    "            epoch_val_loss /= n_folds\n",
    "            epoch_train_loss /= n_folds\n",
    "            val_losses.append(epoch_val_loss.item())\n",
    "            train_losses.append(epoch_train_loss.item())\n",
    "            if includeTests:\n",
    "                test_result = test(nets)\n",
    "                test_losses.append(test_result[\"loss\"])\n",
    "                if len(val_losses) > 1 and (best_test_preds is None or val_losses[-1] < min(val_losses[1:-1])):\n",
    "                    best_test_preds = test_result[\"preds\"]\n",
    "        if prints and epoch % 100 == 0:\n",
    "            print(\"Epoch {}:\\tTrain {}\\tVal {}\\tTest {}\".format(epoch, train_losses[-1], val_losses[-1], test_losses[-1]))\n",
    "        epoch += 1\n",
    "        reference_loss_index = 1000 // epochs_per_validation\n",
    "        if epoch > max(n_points_train_val * 200, 2000) and val_losses[-1] >= val_losses[-reference_loss_index]:\n",
    "            break\n",
    "    \n",
    "    return {\"nets\": nets, \n",
    "            \"train_loss\": train_losses, \n",
    "            \"val_loss\": val_losses, \n",
    "            \"test_loss\": test_losses, \n",
    "            \"best_test_preds\": best_test_preds,\n",
    "            \"epochs\": epochs\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def visualize_train(train_results):\n",
    "    for i, train_result in enumerate(train_results):\n",
    "        plt.plot(train_result[\"epochs\"], train_result[\"train_loss\"], label='Training{}'.format(i))\n",
    "        plt.plot(train_result[\"epochs\"], train_result[\"val_loss\"], label='Validation{}'.format(i))\n",
    "        if len(train_result[\"test_loss\"]):\n",
    "            plt.plot(train_result[\"epochs\"], train_result[\"test_loss\"], label='Test{}'.format(i))\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start calculation for 1 points.\n",
      "Epoch 0:\tTrain 2.0765435695648193\tVal 2.0765435695648193\tTest 1.4820139408111572\n",
      "Epoch 100:\tTrain 0.6795887351036072\tVal 0.6795887351036072\tTest 1.4530706405639648\n",
      "Epoch 200:\tTrain 0.11570004373788834\tVal 0.11570004373788834\tTest 1.6105015277862549\n",
      "Epoch 300:\tTrain 0.0042291306890547276\tVal 0.0042291306890547276\tTest 1.7747589349746704\n",
      "Epoch 400:\tTrain 2.469748505973257e-05\tVal 2.469748505973257e-05\tTest 1.8199201822280884\n",
      "Epoch 500:\tTrain 2.2240023156427924e-08\tVal 2.2240023156427924e-08\tTest 1.8237123489379883\n",
      "Epoch 600:\tTrain 1.7417178810319456e-12\tVal 1.7417178810319456e-12\tTest 1.823828935623169\n",
      "Epoch 700:\tTrain 3.632649736573512e-13\tVal 3.632649736573512e-13\tTest 1.823829174041748\n",
      "Epoch 800:\tTrain 2.353672812205332e-13\tVal 2.353672812205332e-13\tTest 1.823829174041748\n",
      "Epoch 900:\tTrain 1.3589129821411916e-13\tVal 1.3589129821411916e-13\tTest 1.823829174041748\n",
      "Epoch 1000:\tTrain 6.483702463810914e-14\tVal 6.483702463810914e-14\tTest 1.823829174041748\n",
      "Epoch 1100:\tTrain 3.9968028886505635e-14\tVal 3.9968028886505635e-14\tTest 1.8238296508789062\n",
      "Epoch 1200:\tTrain 2.220446049250313e-14\tVal 2.220446049250313e-14\tTest 1.8238296508789062\n",
      "Epoch 1300:\tTrain 1.509903313490213e-14\tVal 1.509903313490213e-14\tTest 1.8238296508789062\n",
      "Epoch 1400:\tTrain 8.881784197001252e-16\tVal 8.881784197001252e-16\tTest 1.8238294124603271\n",
      "Epoch 1500:\tTrain 8.881784197001252e-16\tVal 8.881784197001252e-16\tTest 1.8238294124603271\n",
      "Epoch 1600:\tTrain 8.881784197001252e-16\tVal 8.881784197001252e-16\tTest 1.8238294124603271\n",
      "Epoch 1700:\tTrain 8.881784197001252e-16\tVal 8.881784197001252e-16\tTest 1.8238294124603271\n",
      "Epoch 1800:\tTrain 8.881784197001252e-16\tVal 8.881784197001252e-16\tTest 1.8238294124603271\n",
      "Epoch 1900:\tTrain 8.881784197001252e-16\tVal 8.881784197001252e-16\tTest 1.8238294124603271\n",
      "Epoch 2000:\tTrain 8.881784197001252e-16\tVal 8.881784197001252e-16\tTest 1.8238294124603271\n",
      "Epoch 2100:\tTrain 8.881784197001252e-16\tVal 8.881784197001252e-16\tTest 1.8238294124603271\n",
      "Epoch 2200:\tTrain 8.881784197001252e-16\tVal 8.881784197001252e-16\tTest 1.8238294124603271\n",
      "Epoch 2300:\tTrain 8.881784197001252e-16\tVal 8.881784197001252e-16\tTest 1.8238294124603271\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for n_points_train_val in range(1, 31):\n",
    "    print(\"Start calculation for {} points.\".format(n_points_train_val))\n",
    "    starttime = time.time()\n",
    "    train_result = train(n_points_train_val, l2_loss, includeTests=True, prints=True)\n",
    "    # visualize_train([train_result])\n",
    "    del train_result[\"nets\"]\n",
    "    results.append([n_points_train_val, str(train_result), time.time() - starttime])\n",
    "    if n_points_train_val >= 10 and n_points_train_val % 5 == 0:\n",
    "        df = pd.DataFrame(results, columns=[\"n_points_train_val\", \"train_result\", \"execution_time\"])\n",
    "        df.to_csv(\"train_limited_data_results_{}.csv\".format(n_points_train_val), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add different loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_loss(y_pred, y_true, rotation_matrix):\n",
    "    return (l2_loss(y_pred, (0,0), np.zeros((2,2))) - 1) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def det_loss(y_pred, y_true, rotation_matrix):\n",
    "    det = rotation_matrix[0][0] * rotation_matrix[1][1] - rotation_matrix[0][1] * rotation_matrix[1][0]\n",
    "    return (det - 1) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first weight is for l2_loss, second weight for det_loss, third for norm loss\n",
    "def get_mixed_lossfn(weigths):\n",
    "    def mixed_loss(y_pred, y_true, rotation_matrix):\n",
    "        l0 = l2_loss(y_pred, y_true, rotation_matrix)\n",
    "        l1 = det_loss(y_pred, y_true, rotation_matrix)\n",
    "        l2 = norm_loss(y_pred, y_true, rotation_matrix)\n",
    "        return weigths[0] * l0 + weigths[1] * l1 + weigths[2] * l2\n",
    "    return mixed_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    n_points_train_val = 5\n",
    "    train_result_mixed = train(n_points_train_val, get_mixed_lossfn((1, 2, 4)), includeTests=True, prints=True)\n",
    "    visualize_train([train_result, train_result_mixed])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results: \n",
    "(1, 2, 0.2) is more consistent throughout training\n",
    "(1, 2, 8) is worse\n",
    "(1, 4, 0.2) really bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
