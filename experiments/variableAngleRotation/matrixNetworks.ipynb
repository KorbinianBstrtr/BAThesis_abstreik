{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "#SBATCH --cpus=1\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --mem=20GB\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=abstreik\n",
    "#SBATCH --time=45:00:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../helper')\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import RotationMatrix\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "tqdm = lambda x: x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = pd.read_csv(\"../data/rotated_points_angle.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, n_hidden=None):\n",
    "        super().__init__()\n",
    "        hidden_nodes = 50 if n_hidden is None else n_hidden\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(1, hidden_nodes),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_nodes, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x_batch):\n",
    "        return self.ff(x_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if model can learn sine function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_sin():\n",
    "    random.seed(234)\n",
    "    model = Net()\n",
    "    opt = Adam(model.parameters())\n",
    "    model.train()\n",
    "    for i in tqdm(range(300000)):\n",
    "        alpha = random.uniform(0, 2*math.pi)\n",
    "        pred = model(torch.Tensor([alpha]))\n",
    "        y_true = math.sin(alpha)\n",
    "        opt.zero_grad()\n",
    "        loss = (pred - y_true) ** 2\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_sin_model(model):\n",
    "    test = np.linspace(0, 2*math.pi, 100)\n",
    "    model.eval()\n",
    "    pred = model(torch.Tensor(np.matrix(test).transpose()))\n",
    "    plt.plot(test, np.sin(test))\n",
    "    plt.plot(test, pred.detach().numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_matrix_nets(nets):\n",
    "    test = np.linspace(0, 2*math.pi, 100)\n",
    "    for model in nets:\n",
    "        model.eval()\n",
    "    fig, ax = plt.subplots(2, 2)\n",
    "    ax[0, 0].plot(test, np.cos(test))\n",
    "    ax[0, 0].plot(test, nets[0](torch.Tensor(np.matrix(test).transpose())).detach().numpy())\n",
    "    ax[0, 1].plot(test, -np.sin(test))\n",
    "    ax[0, 1].plot(test, nets[1](torch.Tensor(np.matrix(test).transpose())).detach().numpy())\n",
    "    ax[1, 0].plot(test, np.sin(test))\n",
    "    ax[1, 0].plot(test, nets[2](torch.Tensor(np.matrix(test).transpose())).detach().numpy())\n",
    "    ax[1, 1].plot(test, np.cos(test))\n",
    "    ax[1, 1].plot(test, nets[3](torch.Tensor(np.matrix(test).transpose())).detach().numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot_sin_model(train_sin())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train nets for matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loader(data, shuffle=True):\n",
    "    X = torch.FloatTensor(data[[\"x1\", \"y1\", \"alpha\"]].values)\n",
    "    y = torch.FloatTensor(data[[\"x2\", \"y2\"]].values)\n",
    "    torch_data = TensorDataset(X, y)\n",
    "    loader = DataLoader(torch_data, batch_size=5, shuffle=shuffle)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def l2_loss(y_pred, y_true, rotation_matrix):\n",
    "    return (y_pred[0] - y_true[0]) ** 2 + (y_pred[1] - y_true[1]) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_pred_loss(x_batch, y_batch, nets, loss_fn):\n",
    "    alphas = x_batch[:, [2]]\n",
    "    matrix_entries = [model(alphas) for model in nets]\n",
    "    loss = 0\n",
    "    preds = []\n",
    "    for i in range(len(alphas)):\n",
    "        predx = matrix_entries[0][i] * x_batch[i][0] + matrix_entries[1][i] * x_batch[i][1]\n",
    "        predy = matrix_entries[2][i] * x_batch[i][0] + matrix_entries[3][i] * x_batch[i][1]\n",
    "        loss += loss_fn((predx, predy), y_batch[i], [[matrix_entries[0][i], matrix_entries[1][i]], [matrix_entries[2][i], matrix_entries[3][i]]])\n",
    "        preds.append((predx.item(), predy.item()))\n",
    "    loss /= len(alphas)\n",
    "    return {\"loss\": loss, \"preds\": preds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_loss(x_batch, y_batch, nets, loss_fn):\n",
    "    return calc_pred_loss(x_batch, y_batch, nets, loss_fn)[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"../data/test.csv\")\n",
    "# test_data = test_data[test_data.index % 20 == 0]\n",
    "test_loader = get_loader(test_data, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(net_ensemble, loss_fn=l2_loss, visualizePreds=False):\n",
    "    test_preds = []\n",
    "    test_true = []\n",
    "    all_model_preds = []\n",
    "    avg_test_loss = 0.0\n",
    "    for nets in net_ensemble:\n",
    "        model_preds = []\n",
    "        for model in nets:\n",
    "            model.eval()\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            result = calc_pred_loss(x_batch, y_batch, nets, loss_fn)\n",
    "            model_preds += result[\"preds\"]\n",
    "            avg_test_loss += result[\"loss\"]\n",
    "            test_true += list(y_batch)\n",
    "        all_model_preds.append(model_preds)\n",
    "        if visualizePreds:\n",
    "            print(\"model preds:\")\n",
    "            plot_predictions(model_preds)\n",
    "    avg_test_loss /= len(test_loader) * len(net_ensemble)\n",
    "    for i in range(len(all_model_preds[0])):\n",
    "        predx = 0\n",
    "        predy = 0\n",
    "        for model_preds in all_model_preds:\n",
    "            predx += model_preds[i][0]\n",
    "            predy += model_preds[i][1]\n",
    "        predx /= len(all_model_preds)\n",
    "        predy /= len(all_model_preds)\n",
    "        test_preds.append((predx, predy))\n",
    "    if visualizePreds:\n",
    "        print(\"total preds:\")\n",
    "        plot_predictions(test_preds)\n",
    "    test_loss = 0\n",
    "    for y_pred, y_true in zip(test_preds, test_true):\n",
    "        test_loss += loss_fn(y_pred, y_true, [[float('NaN'), float('NaN')], [float('NaN'), float('NaN')]])\n",
    "    test_loss /= len(test_preds)\n",
    "    return {\"loss\": test_loss.item(), \"preds\": test_preds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(n_points_train_val, loss_fn, includeTests=False, prints=False, lastTrainResult=None, nEpochs=None, minEpochs=8000, hidden_nodes=None):\n",
    "    torch.manual_seed(0)\n",
    "    train_val_points = points.head(n_points_train_val)\n",
    "    n_folds = min(n_points_train_val, 10)\n",
    "    fold_indices = [(range(n_points_train_val), range(n_points_train_val))]\n",
    "    if n_folds > 1:\n",
    "        kf = KFold(n_folds, random_state=0)\n",
    "        fold_indices = kf.split(train_val_points)\n",
    "\n",
    "    train_loader = []\n",
    "    val_loader = []\n",
    "    for train_index, val_index in fold_indices:\n",
    "        train_loader.append(get_loader(points.loc[train_index]))\n",
    "        val_loader.append(get_loader(points.loc[val_index]))\n",
    "    \n",
    "    nets = [[Net(n_hidden=hidden_nodes) for _ in range(4)] for _ in range(n_folds)] if lastTrainResult is None else lastTrainResult[\"nets\"]\n",
    "    opts = []\n",
    "    if lastTrainResult is None:\n",
    "        for matrixnets in nets:\n",
    "            optrow = []\n",
    "            for model in matrixnets:\n",
    "                optrow.append(Adam(model.parameters()))\n",
    "            opts.append(optrow)\n",
    "    else:\n",
    "        opts = lastTrainResult[\"opts\"]\n",
    "    val_losses = [] if lastTrainResult is None else lastTrainResult[\"val_loss\"]\n",
    "    train_losses = [] if lastTrainResult is None else lastTrainResult[\"train_loss\"]\n",
    "    test_losses = [] if lastTrainResult is None else lastTrainResult[\"test_loss\"]\n",
    "    best_test_preds = None if lastTrainResult is None else lastTrainResult[\"best_test_preds\"]\n",
    "    epochs = [] if lastTrainResult is None else lastTrainResult[\"epochs\"]\n",
    "    epoch = 0 if lastTrainResult is None else (epochs[-1] + 1)\n",
    "    start_epoch = epoch\n",
    "    epochs_per_validation = 500#100 if n_points_train_val > 10 else (10 if n_points_train_val > 5 else 3)\n",
    "    while True:\n",
    "        epoch_val_loss = 0\n",
    "        epoch_train_loss = 0\n",
    "        validate = (epoch % epochs_per_validation == 0)\n",
    "        for fold in range(n_folds):\n",
    "            # training\n",
    "            for model in nets[fold]:\n",
    "                model.train()\n",
    "            for x_batch, y_batch in train_loader[fold]:\n",
    "                loss = calc_loss(x_batch, y_batch, nets[fold], loss_fn)\n",
    "                for opt in opts[fold]:\n",
    "                    opt.zero_grad()\n",
    "                loss.backward()\n",
    "                for opt in opts[fold]:\n",
    "                    opt.step()\n",
    "            # validation\n",
    "            if validate:\n",
    "                for model in nets[fold]:\n",
    "                    model.eval()\n",
    "                val_loss = 0\n",
    "                train_loss = 0\n",
    "                for x_batch, y_batch in val_loader[fold]:\n",
    "                    val_loss += calc_loss(x_batch, y_batch, nets[fold], l2_loss)\n",
    "                for x_batch, y_batch in train_loader[fold]:\n",
    "                    train_loss += calc_loss(x_batch, y_batch, nets[fold], loss_fn)\n",
    "                val_loss /= len(val_loader[fold])\n",
    "                train_loss /= len(train_loader[fold])\n",
    "                epoch_val_loss += val_loss\n",
    "                epoch_train_loss += train_loss\n",
    "\n",
    "        if validate:\n",
    "            epochs.append(epoch)\n",
    "            epoch_val_loss /= n_folds\n",
    "            epoch_train_loss /= n_folds\n",
    "            val_losses.append(epoch_val_loss.item())\n",
    "            train_losses.append(epoch_train_loss.item())\n",
    "            if includeTests:\n",
    "                test_result = test(nets, visualizePreds=False)#(epoch%1000 == 0))\n",
    "                test_losses.append(test_result[\"loss\"])\n",
    "                if len(val_losses) > 1 and (best_test_preds is None or val_losses[-1] < min(val_losses[1:-1])):\n",
    "                    best_test_preds = test_result[\"preds\"]\n",
    "        if prints and epoch % 500 == 0:\n",
    "            print(\"Epoch {}:\\tTrain {}\\tVal {}\\tTest {}\".format(epoch, train_losses[-1], val_losses[-1], test_losses[-1]))\n",
    "        epoch += 1\n",
    "        reference_loss_index = 1000 // epochs_per_validation\n",
    "        if (nEpochs is None and epoch > max(n_points_train_val * 200, minEpochs) and val_losses[-1] >= val_losses[-reference_loss_index]) or (nEpochs is not None and epoch - start_epoch > nEpochs):\n",
    "            break\n",
    "    \n",
    "    return {\"nets\": nets, \n",
    "            \"opts\": opts,\n",
    "            \"train_loss\": train_losses, \n",
    "            \"val_loss\": val_losses, \n",
    "            \"test_loss\": test_losses, \n",
    "            \"best_test_preds\": best_test_preds,\n",
    "            \"epochs\": epochs\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def visualize_train(train_results, keys=[\"train_loss\", \"val_loss\", \"test_loss\"]):\n",
    "    for i, train_result in enumerate(train_results):\n",
    "        for key in keys:\n",
    "            plt.plot(train_result[\"epochs\"], train_result[key], label='{}_{}'.format(key, i))\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_predictions(preds):\n",
    "    plt.figure()\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.ylim(-1.2, 1.2)\n",
    "    plt.xlim(-1.2, 1.2)\n",
    "    for i, pred in enumerate(preds):\n",
    "        test_point = test_data.iloc[i]\n",
    "        plt.plot([test_point[\"x1\"], test_point[\"x2\"]], [test_point[\"y1\"], test_point[\"y2\"]], color=\"green\", linewidth=0.5)\n",
    "        plt.plot([pred[0], test_point[\"x2\"]], [pred[1], test_point[\"y2\"]], color=\"red\", linewidth=0.5)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with n points until convergence using l2_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare different numbers of hidden nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_points_train_val = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def try_different_hidden_nodes():\n",
    "    results_hidden_nodes = []\n",
    "    for n_hidden in [5, 10, 20, 50, 100]:\n",
    "        print(\"Start calculation for {} hidden nodes.\".format(n_hidden))\n",
    "        nEpochs = 30000 if n_hidden < 50 else 70000\n",
    "        train_result = train(n_points_train_val, l2_loss, includeTests=True, prints=True, nEpochs=nEpochs, hidden_nodes=n_hidden)\n",
    "        del train_result[\"nets\"]\n",
    "        del train_result[\"opts\"]\n",
    "        results_hidden_nodes.append([n_hidden, str(train_result)])\n",
    "    results_hidden_nodes = pd.DataFrame(results_hidden_nodes, columns=[\"n_hidden\", \"train_result\"])\n",
    "    results_hidden_nodes.to_csv(\"results_hidden_nodes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try_different_hidden_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_hidden_nodes = pd.read_csv(\"results_hidden_nodes.csv\")\n",
    "results_hidden_nodes[\"train_result\"] = results_hidden_nodes.apply(lambda row: eval(row[\"train_result\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize_train(results_hidden_nodes[\"train_result\"], keys=[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: Choose 50 hidden nodes (tradeoff between minimum validation loss and epochs to reach it)\n",
    "Difficulty: Validation loss with few data is unreliable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate for different numbers of points and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def try_different_n_data():\n",
    "    results_limited_data = []\n",
    "    for n_points_train_val in range(1, 36):\n",
    "        print(\"Start calculation for {} points.\".format(n_points_train_val))\n",
    "        train_result = train(n_points_train_val, l2_loss, includeTests=True, prints=True, minEpochs=12000)\n",
    "        del train_result[\"nets\"]\n",
    "        del train_result[\"opts\"]\n",
    "        results_limited_data.append([n_points_train_val, str(train_result)])\n",
    "        if n_points_train_val >= 20 and n_points_train_val % 5 == 0:\n",
    "            df = pd.DataFrame(results_limited_data, columns=[\"n_points_train_val\", \"train_result\"])\n",
    "            df.to_csv(\"train_limited_data_results_{}.csv\".format(n_points_train_val), index=False)\n",
    "    results_limited_data = pd.DataFrame(results_limited_data, columns=[\"n_points_train_val\", \"train_result\"])\n",
    "    results_limited_data.to_csv(\"results_limited_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try_different_n_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_limited_data = pd.read_csv(\"train_limited_data_results_35.csv\", index_col=\"n_points_train_val\")\n",
    "results_limited_data[\"train_result\"] = results_limited_data.apply(lambda row: eval(row[\"train_result\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(results_limited_data.index, results_limited_data.apply(lambda x: min(x[\"train_result\"][\"test_loss\"]), axis=1))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(results_limited_data.index, results_limited_data.apply(lambda x: min(x[\"train_result\"][\"val_loss\"]), axis=1))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: For at least the first 11 data points, the rotation is approximated well, validation loss again does not reflect test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add different loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choose a specific number of points to further experiment with\n",
    "n_points_train_val = 10\n",
    "train_result = results_limited_data[\"train_result\"][n_points_train_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_loss(y_pred, y_true, rotation_matrix):\n",
    "    return (l2_loss(y_pred, (0,0), np.zeros((2,2))) - 1) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def det_loss(y_pred, y_true, rotation_matrix):\n",
    "    det = rotation_matrix[0][0] * rotation_matrix[1][1] - rotation_matrix[0][1] * rotation_matrix[1][0]\n",
    "    return (det - 1) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first weight is for l2_loss, second weight for det_loss, third for norm loss\n",
    "def get_mixed_lossfn(weigths):\n",
    "    def mixed_loss(y_pred, y_true, rotation_matrix):\n",
    "        l0 = l2_loss(y_pred, y_true, rotation_matrix)\n",
    "        l1 = det_loss(y_pred, y_true, rotation_matrix)\n",
    "        l2 = norm_loss(y_pred, y_true, rotation_matrix)\n",
    "        return weigths[0] * l0 + weigths[1] * l1 + weigths[2] * l2\n",
    "    return mixed_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def try_different_det_loss():\n",
    "    results_det_loss = []\n",
    "    for det_loss_weight in [0.4, 1, 2, 3, 4]:\n",
    "        weights = (1, det_loss_weight, 0)\n",
    "        print(\"Start calculation for weights = {}.\".format(weights))\n",
    "        train_result_tmp = train(n_points_train_val, get_mixed_lossfn(weights), includeTests=True, prints=True, nEpochs=40000)\n",
    "        del train_result_tmp[\"nets\"]\n",
    "        del train_result_tmp[\"opts\"]\n",
    "        results_det_loss.append([weights, str(train_result_tmp)])\n",
    "    results_det_loss = pd.DataFrame(results_det_loss, columns=[\"loss_weights\", \"train_result\"])\n",
    "    results_det_loss.to_csv(\"results_det_loss.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try_different_det_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_det_loss = pd.read_csv(\"results_det_loss.csv\")\n",
    "results_det_loss[\"train_result\"] = results_det_loss.apply(lambda row: eval(row[\"train_result\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualize_train(results_det_loss[\"train_result\"], keys=[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def try_different_norm_loss():\n",
    "    results_norm_loss = []\n",
    "    for norm_loss_weight in [0, 0.2, 0.3, 0.4, 0.6, 0.8, 1, 1.5, 2, 2.5]:\n",
    "        weights = (1, 0, norm_loss_weight)\n",
    "        print(\"Start calculation for weights = {}.\".format(weights))\n",
    "        train_result_tmp = train(n_points_train_val, get_mixed_lossfn(weights), includeTests=True, prints=True, nEpochs=40000)\n",
    "        del train_result_tmp[\"nets\"]\n",
    "        del train_result_tmp[\"opts\"]\n",
    "        results_norm_loss.append([weights, str(train_result_tmp)])\n",
    "    results_norm_loss = pd.DataFrame(results_norm_loss, columns=[\"loss_weights\", \"train_result\"])\n",
    "    results_norm_loss.to_csv(\"results_norm_loss.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try_different_norm_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# results_norm_loss = pd.read_csv(\"results_norm_loss.csv\")\n",
    "# results_norm_loss[\"train_result\"] = results_norm_loss.apply(lambda row: eval(row[\"train_result\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUVBKKRWiRUEppVTI/wP6KfDg/2B3hgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x127896518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize_train(results_norm_loss[\"train_result\"], keys=[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_result_mixed = train(n_points_train_val, get_mixed_lossfn((1, 2, 0.2)), includeTests=True, prints=True, nEpochs=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_result_mixed = train(n_points_train_val, get_mixed_lossfn((1, 0.2, 0.1)), includeTests=True, prints=True, nEpochs=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_result_mixed = train(n_points_train_val, get_mixed_lossfn((1, 0, 0.1)), includeTests=True, prints=True, nEpochs=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#visualize_train([train_result, train_result_mixed])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results: \n",
    "(1, 2, 0.2) is better, converges to 0.18 test loss\n",
    "(1, 2, 8) is worse\n",
    "(1, 4, 0.2) really bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEXT: Try different weights, try dynamically changing loss functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
